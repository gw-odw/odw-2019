{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;padding: 1.3em\" src=\"https://indico.in2p3.fr/event/18313/logo-786578160.png\">  \n",
    "\n",
    "#  Gravitational Wave Open Data Workshop #2\n",
    "\n",
    "### Tutorial 2.2: Matched Filtering\n",
    "\n",
    "We will be using the [PyCBC](http://github.com/ligo-cbc/pycbc) library, which is used to study gravitational-wave data, find astrophysical sources due to compact binary mergers, and study their parameters. These are some of the same tools that the LIGO and Virgo collaborations use to find gravitational waves in LIGO/Virgo data \n",
    "\n",
    "In this tutorial we will walk through how find a specific signal in LIGO data. We present how to generate the waveform of a gravitational-wave merger and matched filtering, which is optimal in the case of Gaussian noise and a known signal model. In reality our noise is not entirely Guassian, and in practice we use a variety of techniques to separate signals from noise in addition to the use of the matched filter. \n",
    "\n",
    "[Click this link to view this tutorial in Google Colaboratory](https://colab.research.google.com/github/gw-odw/odw-2019/blob/master/Day_2/Tuto 2.4 MatchedFiltering.ipynb)\n",
    "\n",
    "Additional [examples](http://pycbc.org/pycbc/latest/html/#library-examples-and-interactive-tutorials) and module level documentation are [here](http://pycbc.org/pycbc/latest/html/py-modindex.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation (execute only if running on a cloud platform!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! wget --output-document=requirements.txt 'https://raw.githubusercontent.com/gw-odw/odw-2019/master/requirements.txt'\n",
    "! pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important:** With Google Colab, you may need to restart the runtime after running the cell above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking for a specific signal in the data\n",
    "\n",
    "If you know what signal you are looking for in the data, then matched filtering is known to be the optimal method in Gaussian noise to extract the siganl. Even when the parameters of the signal are unkown,  one can test for each set of parameters one is interesting in finding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preconditioning the data \n",
    " \n",
    "The purpose of this is to reduce the dynamic range of the data and  supress low freqeuncy behavior which can introduce numerical artefacts. We may also wish to resample the data if high frequency content is not important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# As an example we use the GW150914 data\n",
    "from pycbc.catalog import Merger\n",
    "from pycbc.filter import resample_to_delta_t, highpass\n",
    "\n",
    "merger = Merger(\"GW150914\")\n",
    "\n",
    "# Get the data from the Hanford detector\n",
    "strain = merger.strain('H1')\n",
    "\n",
    "# Remove the low frequency content and downsample the data to 2048Hz\n",
    "strain = resample_to_delta_t(highpass(strain, 15.0), 1.0/2048)\n",
    "\n",
    "pylab.plot(strain.sample_times, strain)\n",
    "pylab.xlabel('Time (s)')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### filter wraparound \n",
    "\n",
    "Note the spike in the data at the boundaries. This is caused by the highpass and resampling stages filtering the data. When the filter is applied to the boundaries, it wraps around to the beginning of the data. Since the data itself has a discontinuity (i.e. it is not cyclic) the filter itself will ring off for a time up to the length of the filter. \n",
    "\n",
    "Even if a visible transient is not seen, we want to avoid filters that act on times which are not causally connect. To avoid this we trim the ends of the data sufficiently to ensure that they do not wraparound the input. We will enforce this requirement in all steps of our filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove 2 seconds of data from both the beginning and end\n",
    "conditioned = strain.crop(2, 2)\n",
    "\n",
    "pylab.plot(conditioned.sample_times, conditioned)\n",
    "pylab.xlabel('Time (s)')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate the power spectral density\n",
    "\n",
    "Optimal matched filtering requires weighting the frequency components of the potential signal and data by the noise amplitude. We can view this as filtering the data with the time series equivelant of 1 / PSD. To ensure that we can control how much applying this filter to the data, we window the time domain equivelant of the PSD to a specific length. This has effect of losing some information about line behavior in the detector, however, since our signal span a large frequency range, and lines are narrow, this is a negligible effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pycbc.psd import interpolate, inverse_spectrum_truncation\n",
    "# Estimate the power spectral density\n",
    "\n",
    "# We use 4 second samles of our time series in Welch method.\n",
    "psd = conditioned.psd(4)\n",
    "\n",
    "# Now that we have the psd we need to interpolate it to match our data\n",
    "# and then limit the filter length of 1 / PSD. After this, we can\n",
    "# directly use this PSD to filter the data in a controlled manner\n",
    "\n",
    "psd = interpolate(psd, conditioned.delta_f)\n",
    "\n",
    "# 1/PSD will now act as a filter with an effective length of 4 seconds\n",
    "# Since the data has been highpassed above 15 Hz, and will have low values\n",
    "# below this we need to informat the function to not include frequencies\n",
    "# below this frequency. \n",
    "psd = inverse_spectrum_truncation(psd, 4 * conditioned.sample_rate,\n",
    "                                  low_frequency_cutoff=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make your signal model\n",
    "\n",
    "Conceptually, matched filtering involves laying the potential signal over your data and integrating (after weighting frequencies correctly). If there is a signal in the data that aligns with your 'template', you will get a large value when integrated over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In this case we \"know\" what the signal parameters are. In a search\n",
    "# we would grid over the parameters and calculate the SNR time series\n",
    "# for each one\n",
    "\n",
    "# We'll assume equal masses, which is within the posterior probability\n",
    "# of GW150914. \n",
    "m = 36 # Solar masses\n",
    "hp, hc = get_td_waveform(approximant=\"SEOBNRv4_opt\",\n",
    "                     mass1=m,\n",
    "                     mass2=m,\n",
    "                     delta_t=conditioned.delta_t,\n",
    "                     f_lower=20)\n",
    "\n",
    "# We will resize the vector to match our data\n",
    "hp.resize(len(conditioned))\n",
    "\n",
    "# The waveform begins at the start of the vector, so if we want the\n",
    "# SNR time series to correspond to the approximate merger location\n",
    "# we need to shift the data so that the merger is approximately at the \n",
    "# first bin of the data.\n",
    "\n",
    "# This function rotates the vector by a fixed amount of time.\n",
    "# It treats the data as if it were on a ring. Note that\n",
    "# time stamps are *not* in general affected, but the true\n",
    "# position in the vector is.\n",
    "#\n",
    "# By convention waveforms returned from `get_td_waveform` have their\n",
    "# merger stamped with time zero, so we can use the start time to \n",
    "# shift the merger into position\n",
    "template = hp.cyclic_time_shift(hp.start_time)\n",
    "pylab.plot(template)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculating the signal-to-noise time series\n",
    "\n",
    "In this section we will now calculate the signal-to-noise time series for our template. We'll take care to handle issues of filter corruption / wraparound by truncating the output time series. We need to account for both the length of the template and 1 / PSD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pycbc.filter import matched_filter\n",
    "import numpy\n",
    "\n",
    "snr = matched_filter(template, conditioned,\n",
    "                     psd=psd, low_frequency_cutoff=20)\n",
    "\n",
    "# Remove time corrupted by the template filter and the psd filter\n",
    "# We remove 4 seonds at the beginning and end for the PSD filtering\n",
    "# And we remove 4 additional seconds at the beginning to account for\n",
    "# the template length (this is somewhat generous for \n",
    "# so short a template). A longer signal such as from a BNS, would \n",
    "# require much more padding at the beginning of the vector.\n",
    "snr = snr.crop(4 + 4, 4)\n",
    "\n",
    "# Why am I taking an abs() here?\n",
    "# The `matched_filter` function actually returns a 'complex' SNR.\n",
    "# What that means is that the real portion correponds to the SNR\n",
    "# associated with directly filtering the template with the data.\n",
    "# The imaginary portion corresponds to filtering with a template that\n",
    "# is 90 degrees out of phase. Since the phase of a signal may be \n",
    "# anything, we choose to maximize over the phase of the signal.\n",
    "pylab.figure(figsize=[10, 4])\n",
    "pylab.plot(snr.sample_times, abs(snr))\n",
    "pylab.ylabel('Signal-to-noise')\n",
    "pylab.xlabel('Time (s)')\n",
    "pylab.show()\n",
    "\n",
    "peak = abs(snr).numpy().argmax()\n",
    "snrp = snr[peak]\n",
    "time = snr.sample_times[peak]\n",
    "\n",
    "print(\"We found a signal at {}s with SNR {}\".format(time, \n",
    "                                                    abs(snrp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aligning and Subtracting the Proposed Signal\n",
    "\n",
    "In the previous section we ound a peak in the signal-to-noise for a proposed binary black hole merger. We can use this SNR peak to align our proposal to the data, and to also subtract our proposal from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pycbc.filter import sigma\n",
    "# The time, amplitude, and phase of the SNR peak tell us how to align\n",
    "# our proposed signal with the data.\n",
    "\n",
    "# Shift the template to the peak time\n",
    "dt = time - conditioned.start_time\n",
    "aligned = template.cyclic_time_shift(dt)\n",
    "\n",
    "# scale the template so that it would have SNR 1 in this data\n",
    "aligned /= sigma(aligned, psd=psd, low_frequency_cutoff=20.0)\n",
    "\n",
    "# Scale the template amplitude and phase to the peak value\n",
    "aligned = (aligned.to_frequencyseries() * snrp).to_timeseries()\n",
    "aligned.start_time = conditioned.start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the overlap between the signal and data\n",
    "\n",
    "To compare the data an signal on equal footing, and to concentrate on the frequency range that is important. We will whiten both the template and the data, and then bandpass both the data and template between 30-300 Hz. In this way, any signal that is in the data is transformed in the same way that the template is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We do it this way so that we can whiten both the template and the data\n",
    "white_data = (conditioned.to_frequencyseries() / psd**0.5).to_timeseries()\n",
    "\n",
    "# apply a smoothing of the turnon of the template to avoid a transient\n",
    "# from the sharp turn on in the waveform.\n",
    "tapered = aligned.highpass_fir(30, 512, remove_corrupted=False)\n",
    "white_template = (tapered.to_frequencyseries() / psd**0.5).to_timeseries()\n",
    "\n",
    "white_data = white_data.highpass_fir(30., 512).lowpass_fir(300, 512)\n",
    "white_template = white_template.highpass_fir(30, 512).lowpass_fir(300, 512)\n",
    "\n",
    "# Select the time around the merger\n",
    "white_data = white_data.time_slice(merger.time-.2, merger.time+.1)\n",
    "white_template = white_template.time_slice(merger.time-.2, merger.time+.1)\n",
    "\n",
    "pylab.figure(figsize=[15, 3])\n",
    "pylab.plot(white_data.sample_times, white_data, label=\"Data\")\n",
    "pylab.plot(white_template.sample_times, white_template, label=\"Template\")\n",
    "pylab.legend()\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subtracting the signal from the data\n",
    "\n",
    "Now that we've aligned the template we can simply subtract it. Let's see below how that looks in the time-frequency plots!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subtracted = conditioned - aligned\n",
    "\n",
    "# Plot the original data and the subtracted signal data\n",
    "\n",
    "for data, title in [(conditioned, 'Original H1 Data'),\n",
    "                    (subtracted, 'Signal Subtracted from H1 Data')]:\n",
    "\n",
    "    t, f, p = data.whiten(4, 4).qtransform(.001,\n",
    "                                                  logfsteps=100,\n",
    "                                                  qrange=(8, 8),\n",
    "                                                  frange=(20, 512))\n",
    "    pylab.figure(figsize=[15, 3])\n",
    "    pylab.title(title)\n",
    "    pylab.pcolormesh(t, f, p**0.5, vmin=1, vmax=6)\n",
    "    pylab.yscale('log')\n",
    "    pylab.xlabel('Time (s)')\n",
    "    pylab.ylabel('Frequency (Hz)')\n",
    "    pylab.xlim(merger.time - 2, merger.time + 1)\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge!\n",
    "\n",
    "Use the methods demonstrated above to see if you can calculate the SNR\n",
    "time series in the following data sets. What is the SNR of each signal?\n",
    "Which template matched which data?\n",
    "\n",
    "Information that may be useful:\n",
    "\n",
    "* Signals are all placed between 100 and 120 seconds into the frame file.\n",
    "* You may assume mass1 = mass1 (equal mass) and that each component mass is one of 22, 36, or 50.\n",
    "* Each file starts at gps time 0, and ends at gps time 128\n",
    "* The channel name in each file is \"H1:TEST-STRAIN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download the challenge set files\n",
    "\n",
    "import urllib\n",
    "\n",
    "def get_file(fname):\n",
    "    url = \"https://github.com/ahnitz/odw-storage/raw/master/{}\"\n",
    "    url = url.format(fname)\n",
    "    urllib.urlretrieve(url, fname)\n",
    "    print('Getting : {}'.format(url))\n",
    "\n",
    "files = ['PyCBC_T2_0.gwf', 'PyCBC_T2_2.gwf', 'PyCBC_T2_3.gwf']\n",
    "\n",
    "for fname in files:\n",
    "    get_file(fname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
